{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read(path):\n",
    "  return mpimg.imread(path)\n",
    "\n",
    "def show(image):\n",
    "  print('This image is:', type(image), 'with dimensions:', image.shape)\n",
    "  plt.imshow(image)\n",
    "\n",
    "def save(image, path = 'test.png'):\n",
    "  plt.imsave(path, image)\n",
    "\n",
    "def convert_to_color(image):\n",
    "  return np.dstack((image, image, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gray(raw_image):\n",
    "  '''convert the colored imaged to grayscale image'''\n",
    "  return cv2.cvtColor(raw_image, cv2.COLOR_RGB2GRAY)  \n",
    "\n",
    "def reduce_noise(gray_image, kernel_size):\n",
    "  '''reduce noise of grayscale image using gausian blur'''\n",
    "  return cv2.GaussianBlur(gray_image, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_edges(blur_image, low_threshold, high_threshold):\n",
    "  '''find edges using canny transform algorithm'''\n",
    "  return cv2.Canny(blur_image, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_vertices(x, y, axc, bxc, cyc, dyc, maxyc = 1.0, maxxc = 1.0, startxc = 0.0):\n",
    "  ax = int(axc*x)\n",
    "  bx = int(bxc*x)\n",
    "  cy = int(cyc*y)\n",
    "  dy = int(dyc*y)\n",
    "  maxy = int(maxyc*y)\n",
    "  maxx = int(maxxc*x)\n",
    "  startx = int(startxc*x)\n",
    "  bottom_left = (startx, maxy)\n",
    "  top_left = (ax, cy)\n",
    "  top_right = (bx, dy)\n",
    "  bottom_right = (maxx, maxy)\n",
    "  vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "  return vertices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_roi(edge_image, vertices, ignore_value = 255):\n",
    "  '''get the polygon to be used to block out everything in the image except the region of interest'''\n",
    "  roi = np.zeros_like(edge_image)\n",
    "  cv2.fillPoly(roi, vertices, ignore_value)\n",
    "  return roi\n",
    "\n",
    "def mask(edge_image, roi):\n",
    "  '''block out everything in the image except the edges in the region of interest'''\n",
    "  return cv2.bitwise_and(edge_image, roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_lines(masked_edge_image, rho, theta_coef, min_votes, min_line_length, max_line_gap):\n",
    "  '''convert edges into lines using hough transform algorithm '''\n",
    "  theta = theta_coef*np.pi/180\n",
    "  return cv2.HoughLinesP(masked_edge_image, rho, theta, min_votes, np.array([]), minLineLength = min_line_length, maxLineGap = max_line_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw(lines, image, color=[255, 0, 0], thickness = 2, thresh = 0.5):\n",
    "  ''' draw the lines on a blank image'''\n",
    "  lined_image = np.copy(image)*0\n",
    "  \n",
    "  if lines is not None:\n",
    "    for line in lines:\n",
    "      for x1,y1,x2,y2 in line:\n",
    "        slope, intercept = np.polyfit((x1,x2), (y1,y2), 1)\n",
    "        if abs(slope) > thresh:\n",
    "          cv2.line(lined_image, (x1, y1), (x2, y2), color, thickness)\n",
    "        \n",
    "  return lined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# equation of a line: y = slope*x + intercept \n",
    "# left lane has a positive slope, right lane has a negative slope \n",
    "\n",
    "def extrapolate_lines(lines, image, color=[255, 0, 0], thickness = 10, \n",
    "                      positive_thresh = 0.5, negative_thresh = 0.5):\n",
    "    \n",
    "  imshape = image.shape\n",
    "  image = np.copy(image)*0\n",
    "    \n",
    "  #initialize minimum and maximum y coordinate \n",
    "  minimum_y = image.shape[0] \n",
    "  maximum_y = image.shape[0]\n",
    "  \n",
    "  #initialize groups of values into empty lists\n",
    "  left_slopes = []\n",
    "  left_xs = []\n",
    "  left_ys = []   \n",
    "  right_slopes = []\n",
    "  right_xs = []\n",
    "  right_ys = []\n",
    "  \n",
    "  # segregate the small line segments into the left lane group or right lane group\n",
    "  if lines is not None:  \n",
    "    for line in lines:\n",
    "      for x1,y1,x2,y2 in line:\n",
    "        \n",
    "        # get the slope and intercept of the line (as defined by two points) using the polyfit function\n",
    "        slope, intercept = np.polyfit((x1,x2), (y1,y2), 1)\n",
    "            \n",
    "        if (slope > positive_thresh): #if positive slope, put value to left lane group\n",
    "          left_slopes += [slope]\n",
    "          left_xs += [x1, x2]\n",
    "          left_ys += [y1, y2]\n",
    "        elif (slope < negative_thresh): #if negative slope, put value to right lane group\n",
    "          right_slopes += [slope]\n",
    "          right_xs += [x1, x2]\n",
    "          right_ys += [y1, y2]\n",
    "        \n",
    "        # update the minimum y_coordinate based on values seen\n",
    "        minimum_y = min(min(y1, y2), minimum_y)\n",
    "  \n",
    "  #average all the values in each group to get the slope, x, and y\n",
    "  left_slope = np.mean(left_slopes)\n",
    "  left_x = np.mean(left_xs)\n",
    "  left_y = np.mean(left_ys)\n",
    "  right_slope = np.mean(right_slopes)\n",
    "  right_x = np.mean(right_xs)\n",
    "  right_y = np.mean(right_ys)\n",
    "    \n",
    "  #derive the intercept using the equation of the line and average value\n",
    "  left_intercept = left_y - (left_slope * left_x)\n",
    "  right_intercept = right_y - (right_slope * right_x)\n",
    "\n",
    "  if ((len(left_slopes) > 0) and (len(right_slopes) > 0)): #make sure we have points in each group\n",
    "    #derive the x coordinate using the equation of the lines and derived values\n",
    "    upper_left_x = int((minimum_y - left_intercept) / left_slope)\n",
    "    lower_left_x = int((maximum_y - left_intercept) / left_slope)\n",
    "    upper_right_x = int((minimum_y - right_intercept) / right_slope)\n",
    "    lower_right_x = int((maximum_y - right_intercept) / right_slope)\n",
    "    \n",
    "    #draw the line based on two points \n",
    "    cv2.line(image, (upper_left_x, minimum_y), (lower_left_x, maximum_y), color, thickness)\n",
    "    cv2.line(image, (upper_right_x, minimum_y), (lower_right_x, maximum_y), color, thickness)\n",
    "    \n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def overlap(first_image, second_image, α = 0.8, β = 0.5, λ = 0.0):\n",
    "    '''first_image * α + second_image * β + λ (colored)'''\n",
    "    return cv2.addWeighted(first_image, α, second_image, β, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "   #blur parameters\n",
    "  'kernel_size': 5, \n",
    "    \n",
    "   #canny transform parameters\n",
    "  'canny_lo': 100, \n",
    "  'canny_hi': 200, \n",
    "\n",
    "  #region of interest parameters\n",
    "  'ax_coef': 10.0/25,\n",
    "  'bx_coef': 14.0/25,\n",
    "  'cy_coef': 0.6,\n",
    "  'dy_coef': 0.6,\n",
    "  'maxy_coef': 1.0,\n",
    "  'maxx_coef': 1.0,\n",
    "  'startx_coef': 0.0,\n",
    "\n",
    "  #hough parameters\n",
    "  'rho': 1, \n",
    "  'theta_coef': 1, \n",
    "  'min_votes': 30, \n",
    "  'min_line_length': 20, \n",
    "  'max_line_gap': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pipeline(path, file, name, param = param):\n",
    "    \n",
    "  name = path + name\n",
    "\n",
    "  raw_image = read(path + file)\n",
    "  image = read(path + file)\n",
    "  save(image, path = name + '1-raw.png')\n",
    "  \n",
    "  gray_image = gray(image)\n",
    "  save(gray_image, path = name + '2-grey.png')\n",
    "    \n",
    "  blur_image = reduce_noise(gray_image, param['kernel_size'])\n",
    "  save(blur_image, path = name + '3-blur.png')\n",
    "    \n",
    "  edge_image = get_edges(blur_image, param['canny_lo'], param['canny_hi'])\n",
    "  save(edge_image, path = name + '4-edges.png')\n",
    "  \n",
    "  x = image.shape[1]\n",
    "  y = image.shape[0]\n",
    "  vertices = get_vertices(x, y, param['ax_coef'], param['bx_coef'],\n",
    "                                param['cy_coef'], param['dy_coef'],\n",
    "                                param['maxy_coef'], param['maxx_coef'], param['startx_coef'])\n",
    "  \n",
    "  roi = get_roi(edge_image, vertices)\n",
    "  save(roi, path = name + '5-roi.png')\n",
    "  \n",
    "  mask_image = mask(edge_image, roi)\n",
    "  save(mask_image, path = name + '6-mask.png')\n",
    "  \n",
    "  lines = get_lines(mask_image, param['rho'], param['theta_coef'],\n",
    "                           param['min_votes'], param['min_line_length'],\n",
    "                           param['max_line_gap'])\n",
    "   \n",
    "  line_image = draw(lines, raw_image)\n",
    "  save(line_image, path = name + '7-lines.png')\n",
    "  \n",
    "  \n",
    "  line_image2 = extrapolate_lines(lines, raw_image)\n",
    "  save(line_image2, path = name + '8-lines.png')\n",
    "\n",
    "  image = overlap(line_image, raw_image)\n",
    "  save(image, path = name + '9-overlap.png')\n",
    "\n",
    "  image = overlap(line_image2, raw_image)\n",
    "  save(image, path = name + '10-overlap.png')\n",
    "   \n",
    "\n",
    "pipeline(path = 'test_images/', file = 'solidWhiteCurve.jpg', name = 'A')\n",
    "pipeline(path = 'test_images/', file = 'solidWhiteRight.jpg', name = 'B')\n",
    "pipeline(path = 'test_images/', file = 'solidYellowCurve.jpg', name = 'C')\n",
    "pipeline(path = 'test_images/', file = 'solidYellowCurve2.jpg', name = 'D')\n",
    "pipeline(path = 'test_images/', file = 'solidYellowLeft.jpg', name = 'E')\n",
    "pipeline(path = 'test_images/', file = 'whiteCarLaneSwitch.jpg', name = 'F')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "\n",
    "  raw_image = np.copy(image)\n",
    "  gray_image = gray(image)    \n",
    "  blur_image = reduce_noise(gray_image, param['kernel_size'])\n",
    "    \n",
    "  edge_image = get_edges(blur_image, param['canny_lo'], param['canny_hi'])\n",
    "  \n",
    "  x, y = image.shape[1], image.shape[0]\n",
    "  vertices = get_vertices(x, y, param['ax_coef'], param['bx_coef'],\n",
    "                                param['cy_coef'], param['dy_coef'],\n",
    "                                param['maxx_coef'], param['maxy_coef'],\n",
    "                                param['startx_coef'])\n",
    "  roi = get_roi(edge_image, vertices)  \n",
    "  mask_image = mask(edge_image, roi)\n",
    "  \n",
    "  lines = get_lines(mask_image, param['rho'], param['theta_coef'],\n",
    "                           param['min_votes'], param['min_line_length'],\n",
    "                           param['max_line_gap'])\n",
    "   \n",
    "  #line_image = draw(lines, raw_image)  \n",
    "  #result = overlap(line_image, raw_image)\n",
    " \n",
    "  line_image2 = extrapolate_lines(lines, raw_image) \n",
    "  result = overlap(line_image2, raw_image)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:06<00:00, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 3.32 s, sys: 917 ms, total: 4.23 s\n",
      "Wall time: 7.92 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:28<00:00, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 11.1 s, sys: 3.01 s, total: 14.1 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p = {\n",
    "   #blur parameters\n",
    "  'kernel_size': 3, \n",
    "    \n",
    "   #canny transform parameters\n",
    "  'canny_lo': 50, \n",
    "  'canny_hi': 150, \n",
    "\n",
    "  #region of interest parameters\n",
    "  'ax_coef': 0.41,\n",
    "  'bx_coef': 0.60,\n",
    "  'cy_coef': 0.65,\n",
    "  'dy_coef': 0.65,\n",
    "  'maxy_coef': 0.9,\n",
    "  'maxx_coef': 0.85,\n",
    "  'startx_coef': 0.15,\n",
    "\n",
    "  #hough parameters\n",
    "  'rho': 1, \n",
    "  'theta_coef': 1, \n",
    "  'min_votes': 20, \n",
    "  'min_line_length': 50, \n",
    "  'max_line_gap': 20\n",
    "}\n",
    "\n",
    "def process(image):\n",
    "\n",
    "  raw_image = np.copy(image)\n",
    "\n",
    "  gray_image = gray(image)    \n",
    "  blur_image = reduce_noise(gray_image, p['kernel_size'])\n",
    "    \n",
    "  edge_image = get_edges(blur_image, p['canny_lo'], p['canny_hi'])\n",
    "  \n",
    "  #return convert_to_color(edge_image) #check if canny parameters detect edges of lanes\n",
    "\n",
    "  x = image.shape[1]\n",
    "  y = image.shape[0]\n",
    "  vertices = get_vertices(x, y, p['ax_coef'], p['bx_coef'],\n",
    "                                p['cy_coef'], p['dy_coef'],\n",
    "                                p['maxy_coef'], p['maxx_coef'], p['startx_coef'])\n",
    "  \n",
    "  roi = get_roi(edge_image, vertices)\n",
    "  mask_image = mask(edge_image, roi)\n",
    "  \n",
    "  #return overlap(convert_to_color(roi), raw_image) #check if roi is good\n",
    "    \n",
    "  lines = get_lines(mask_image, p['rho'], p['theta_coef'],\n",
    "                                p['min_votes'], p['min_line_length'],\n",
    "                                p['max_line_gap'], )\n",
    "   \n",
    "  #line_image = draw(lines, raw_image, thresh = 0.5)  \n",
    "  #result = overlap(line_image, raw_image)\n",
    " \n",
    "  line_image2 = extrapolate_lines(lines, raw_image, \n",
    "                                  positive_thresh = 0.5, negative_thresh = -0.5) \n",
    "  result = overlap(line_image2, raw_image)\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra.mp4\n",
      "[MoviePy] Writing video extra.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:16<00:00, 15.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra.mp4 \n",
      "\n",
      "CPU times: user 6.35 s, sys: 1.68 s, total: 8.03 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
